{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "authentic-smell",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-29T03:08:24.485901Z",
     "iopub.status.busy": "2021-07-29T03:08:24.485295Z",
     "iopub.status.idle": "2021-07-29T03:08:26.380626Z",
     "shell.execute_reply": "2021-07-29T03:08:26.379499Z",
     "shell.execute_reply.started": "2021-07-28T09:42:57.81613Z"
    },
    "papermill": {
     "duration": 1.923415,
     "end_time": "2021-07-29T03:08:26.380845",
     "exception": false,
     "start_time": "2021-07-29T03:08:24.457430",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch \n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "proper-correlation",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-29T03:08:26.422340Z",
     "iopub.status.busy": "2021-07-29T03:08:26.421733Z",
     "iopub.status.idle": "2021-07-29T03:08:27.321084Z",
     "shell.execute_reply": "2021-07-29T03:08:27.320508Z",
     "shell.execute_reply.started": "2021-07-28T09:42:59.775373Z"
    },
    "papermill": {
     "duration": 0.922262,
     "end_time": "2021-07-29T03:08:27.321221",
     "exception": false,
     "start_time": "2021-07-29T03:08:26.398959",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import transformers\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "import os\n",
    "import random\n",
    "import pickle\n",
    "from collections import OrderedDict, defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "capital-glossary",
   "metadata": {
    "papermill": {
     "duration": 0.016586,
     "end_time": "2021-07-29T03:08:27.355621",
     "exception": false,
     "start_time": "2021-07-29T03:08:27.339035",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Pairs Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fiscal-negotiation",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-29T03:08:27.402570Z",
     "iopub.status.busy": "2021-07-29T03:08:27.401809Z",
     "iopub.status.idle": "2021-07-29T03:08:27.405020Z",
     "shell.execute_reply": "2021-07-29T03:08:27.405451Z",
     "shell.execute_reply.started": "2021-07-28T09:43:00.653896Z"
    },
    "papermill": {
     "duration": 0.032695,
     "end_time": "2021-07-29T03:08:27.405598",
     "exception": false,
     "start_time": "2021-07-29T03:08:27.372903",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_model_preds(model_paths, input_ids, attention_masks):\n",
    "    \n",
    "    dataset = TensorDataset(input_ids, attention_masks)\n",
    "    dataloader = DataLoader(dataset, batch_size=128, pin_memory=True)\n",
    "\n",
    "    preds_list = []\n",
    "\n",
    "    for fold in range(len(model_paths)):\n",
    "\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(\n",
    "                                                   model_paths[fold], \n",
    "                                                   num_labels = 1,\n",
    "                                                   output_attentions = False,\n",
    "                                                   output_hidden_states = False, \n",
    "                                                   ).to(device)\n",
    "        model.eval()\n",
    "\n",
    "        preds = []\n",
    "        \n",
    "        for batch in tqdm(dataloader):\n",
    "            \n",
    "            with torch.no_grad(): \n",
    "    \n",
    "                output = model(batch[0].to(device), batch[1].to(device))\n",
    "                output = output.logits.detach().cpu().numpy().ravel().tolist()\n",
    "                preds.extend(output)\n",
    "    \n",
    "        del model\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        \n",
    "        preds_list.append(preds)      \n",
    "\n",
    "    return np.array(preds_list)\n",
    "\n",
    "\n",
    "def auto_tokenize(data, tokenizer_dir, num_tokens):\n",
    "\n",
    "    data = data.to_list()\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(tokenizer_dir)\n",
    "\n",
    "    encoded_input = tokenizer(\n",
    "                              data, \n",
    "                              padding='max_length', \n",
    "                              truncation=True, \n",
    "                              max_length=num_tokens, \n",
    "                              return_tensors='pt'\n",
    "                              )\n",
    "\n",
    "    input_ids = encoded_input['input_ids']\n",
    "    attention_masks = encoded_input['attention_mask']\n",
    "\n",
    "    return input_ids, attention_masks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "pointed-seller",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-29T03:08:27.463737Z",
     "iopub.status.busy": "2021-07-29T03:08:27.463123Z",
     "iopub.status.idle": "2021-07-29T03:08:27.467215Z",
     "shell.execute_reply": "2021-07-29T03:08:27.466782Z",
     "shell.execute_reply.started": "2021-07-28T09:43:00.665858Z"
    },
    "papermill": {
     "duration": 0.038537,
     "end_time": "2021-07-29T03:08:27.467333",
     "exception": false,
     "start_time": "2021-07-29T03:08:27.428796",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "BASE_PATH = '../input'\n",
    "BASE2_PATH = '../input/d/eduardopeynetti'\n",
    "DATA_PATH = '../input/commonlitreadabilityprize'\n",
    "KFOLD1_PATH = BASE_PATH + '/baseline-kfold1'\n",
    "KFOLD2_PATH = BASE_PATH + '/baseline-kfold2'\n",
    "KFOLD_RESIDUAL_PATH = BASE_PATH + '/roberta-kfold-residual'\n",
    "KFOLD_RESIDUAL_300_PATH = BASE_PATH + '/residual-300-tokens'\n",
    "ELECTRA_RESIDUAL_PATH = BASE_PATH + '/electra-kfold-residual'\n",
    "DEBERTA_KFOLD1_PATH = BASE_PATH + '/deberta-kfold1'\n",
    "DEBERTA_KFOLD2_PATH = BASE2_PATH + '/deberta-kfold2' \n",
    "DEBERTA_RESIDUAL_300_PATH = BASE_PATH + '/deberta-kfold-residual' \n",
    "\n",
    "HUGGING_PATH = BASE_PATH + '/commonlit-huggingface'\n",
    "\n",
    "TRAIN_PATH = DATA_PATH + '/' + 'train.csv'\n",
    "TEST_PATH = DATA_PATH + '/' + 'test.csv'\n",
    "SAMPLE_PATH = DATA_PATH + '/' + 'sample_submission.csv'\n",
    "\n",
    "DEBERTA_PATH = HUGGING_PATH + '/' +'deberta-tokenizer'\n",
    "ELECTRA_PATH = HUGGING_PATH + '/' +'electra_tokenizer'\n",
    "ROBERTA_PATH = HUGGING_PATH + '/' +'roberta-tokenizer'\n",
    "\n",
    "# Fold 1\n",
    "\n",
    "MODEL0_KFOLD1_PATH = KFOLD1_PATH + '/baseline_kfold1_fold0'    #0.476\n",
    "MODEL2_KFOLD1_PATH = KFOLD1_PATH + '/baseline_kfold1_fold2'    #0.475\n",
    "MODEL3_KFOLD1_PATH = KFOLD1_PATH + '/baseline_kfold1_fold3'    #0.469\n",
    "MODEL4_KFOLD1_PATH = KFOLD1_PATH + '/baseline_kfold1_fold4'    #0.473\n",
    "\n",
    "MODEL_EXTRA_KFOLD1_PATH = KFOLD1_PATH + '/pairs_large_fold3'   #0.474\n",
    "\n",
    "# Fold 2\n",
    "\n",
    "MODEL2_KFOLD2_PATH = KFOLD2_PATH + '/baseline_kfold2_fold2'    #0.472\n",
    "MODEL4_KFOLD2_PATH = KFOLD2_PATH + '/baseline_kfold2_fold4'    #0.472   \n",
    "\n",
    "# Residual\n",
    "\n",
    "RESIDUAL0_PATH = KFOLD_RESIDUAL_PATH + '/model1_fold0'         #0.472\n",
    "RESIDUAL4_300_PATH = KFOLD_RESIDUAL_300_PATH + '/fold4model4'  #0.472\n",
    "\n",
    "RESIDUAL_REINIT_PATH = '../input/pairs-reinit/kfold1_fold3'\n",
    "\n",
    "# Electra\n",
    "\n",
    "ELECTRA0_PATH = ELECTRA_RESIDUAL_PATH + '/fold0model3'\n",
    "ELECTRA3_PATH = ELECTRA_RESIDUAL_PATH + '/fold3model3'\n",
    "ELECTRA4_PATH = ELECTRA_RESIDUAL_PATH + '/electra_mlm_fold4'\n",
    "\n",
    "# Deberta\n",
    "\n",
    "DEBERTA0_KFOLD1_PATH = DEBERTA_KFOLD1_PATH + '/deberta_kfold1_fold0'\n",
    "DEBERTA3_KFOLD1_PATH = DEBERTA_KFOLD1_PATH + '/deberta_kfold1_fold3'\n",
    "DEBERTA2_KFOLD2_PATH = DEBERTA_KFOLD2_PATH + '/deberta_kfold2_fold2'\n",
    "\n",
    "DEBERTA1_RESIDUAL_PATH = DEBERTA_RESIDUAL_300_PATH + '/deberta_fold1_model2'\n",
    "\n",
    "            \n",
    "# Ensemble\n",
    "\n",
    "\n",
    "BASELINE_MODEL_PATHS = [MODEL0_KFOLD1_PATH, MODEL2_KFOLD1_PATH, MODEL3_KFOLD1_PATH, MODEL3_KFOLD1_PATH,\n",
    "                        MODEL4_KFOLD1_PATH, MODEL_EXTRA_KFOLD1_PATH,\n",
    "                        MODEL2_KFOLD2_PATH, MODEL4_KFOLD2_PATH]\n",
    "\n",
    "BEST_RESIDUAL_PATHS = [ RESIDUAL0_PATH, RESIDUAL0_PATH]\n",
    "BEST_RESIDUAL_300_PATHS = [RESIDUAL4_300_PATH, RESIDUAL4_300_PATH]\n",
    "\n",
    "DEBERTA_OLD_PATHS = [DEBERTA0_KFOLD1_PATH, DEBERTA3_KFOLD1_PATH, DEBERTA2_KFOLD2_PATH]\n",
    "DEBERTA_RESIDUAL_300_PATHS = [DEBERTA1_RESIDUAL_PATH]\n",
    "\n",
    "ELECTRA_RESIDUAL_300_PATHS = [ELECTRA0_PATH, ELECTRA3_PATH, ELECTRA4_PATH]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "original-detail",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-29T03:08:27.506042Z",
     "iopub.status.busy": "2021-07-29T03:08:27.505471Z",
     "iopub.status.idle": "2021-07-29T03:08:27.525637Z",
     "shell.execute_reply": "2021-07-29T03:08:27.525221Z",
     "shell.execute_reply.started": "2021-07-28T09:43:00.680891Z"
    },
    "papermill": {
     "duration": 0.041196,
     "end_time": "2021-07-29T03:08:27.525775",
     "exception": false,
     "start_time": "2021-07-29T03:08:27.484579",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv(TEST_PATH)\n",
    "sample = pd.read_csv(SAMPLE_PATH)\n",
    "test_x = test.excerpt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "internal-cheat",
   "metadata": {
    "papermill": {
     "duration": 0.016421,
     "end_time": "2021-07-29T03:08:27.559581",
     "exception": false,
     "start_time": "2021-07-29T03:08:27.543160",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "sufficient-walker",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-29T03:08:27.600266Z",
     "iopub.status.busy": "2021-07-29T03:08:27.599616Z",
     "iopub.status.idle": "2021-07-29T03:15:16.697837Z",
     "shell.execute_reply": "2021-07-29T03:15:16.697390Z",
     "shell.execute_reply.started": "2021-07-28T09:43:00.71132Z"
    },
    "papermill": {
     "duration": 409.121691,
     "end_time": "2021-07-29T03:15:16.697981",
     "exception": false,
     "start_time": "2021-07-29T03:08:27.576290",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.16s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.35it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.46it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.70it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.71it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.34it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.70it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.24it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.44it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.70it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.99it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.68it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.29it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.74it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.97it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.79it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.02it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.79it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c0f722661</td>\n",
       "      <td>-0.291971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f0953f0a5</td>\n",
       "      <td>-0.526356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0df072751</td>\n",
       "      <td>-0.597451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04caf4e0c</td>\n",
       "      <td>-2.294861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0e63f8bea</td>\n",
       "      <td>-1.865334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12537fe78</td>\n",
       "      <td>-1.184783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>965e592c0</td>\n",
       "      <td>0.254294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id    target\n",
       "0  c0f722661 -0.291971\n",
       "1  f0953f0a5 -0.526356\n",
       "2  0df072751 -0.597451\n",
       "3  04caf4e0c -2.294861\n",
       "4  0e63f8bea -1.865334\n",
       "5  12537fe78 -1.184783\n",
       "6  965e592c0  0.254294"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roberta_input_ids, roberta_attention_masks = auto_tokenize(test_x, ROBERTA_PATH, 256)\n",
    "deberta_input_ids, deberta_attention_masks = auto_tokenize(test_x, DEBERTA_PATH, 256)\n",
    "roberta_300_input_ids, roberta_300_attention_masks = auto_tokenize(test_x, ROBERTA_PATH, 300)\n",
    "electra_300_input_ids, electra_300_attention_masks = auto_tokenize(test_x, ELECTRA_PATH, 300)\n",
    "deberta_300_input_ids, deberta_300_attention_masks = auto_tokenize(test_x, DEBERTA_PATH, 300)\n",
    "\n",
    "roberta_baseline_preds = get_model_preds(BASELINE_MODEL_PATHS, \n",
    "                                         roberta_input_ids, \n",
    "                                         roberta_attention_masks,\n",
    "                                         )\n",
    "\n",
    "roberta_residual_preds = get_model_preds(BEST_RESIDUAL_PATHS, \n",
    "                                         roberta_input_ids, \n",
    "                                         roberta_attention_masks,\n",
    "                                         )\n",
    "\n",
    "roberta_residual_300_preds = get_model_preds(BEST_RESIDUAL_300_PATHS, \n",
    "                                             roberta_300_input_ids, \n",
    "                                             roberta_300_attention_masks,\n",
    "                                            )\n",
    "                                            \n",
    "deberta_old_preds = get_model_preds(DEBERTA_OLD_PATHS, \n",
    "                                deberta_input_ids, \n",
    "                                deberta_attention_masks,\n",
    "                                )\n",
    "\n",
    "\n",
    "electra_300_preds = get_model_preds(ELECTRA_RESIDUAL_300_PATHS, \n",
    "                                    electra_300_input_ids, \n",
    "                                    electra_300_attention_masks,\n",
    "                                    )\n",
    "\n",
    "electra_preds = [electra_300_preds.mean(axis=0), electra_300_preds.mean(axis=0)]\n",
    "\n",
    "\n",
    "sample['target'] = np.concatenate([roberta_baseline_preds, \n",
    "                                   roberta_residual_preds,\n",
    "                                   roberta_residual_300_preds,\n",
    "                                   deberta_old_preds,\n",
    "                                   electra_preds,\n",
    "                                  ]).mean(axis=0)\n",
    "\n",
    "sample.to_csv(\"submission.csv\",index=False)\n",
    "pairs_pred_df = sample\n",
    "pairs_pred_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "joint-christian",
   "metadata": {
    "papermill": {
     "duration": 0.036683,
     "end_time": "2021-07-29T03:15:16.771363",
     "exception": false,
     "start_time": "2021-07-29T03:15:16.734680",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Regression approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "turkish-advancement",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-29T03:15:16.951088Z",
     "iopub.status.busy": "2021-07-29T03:15:16.950268Z",
     "iopub.status.idle": "2021-07-29T03:15:16.953593Z",
     "shell.execute_reply": "2021-07-29T03:15:16.954016Z",
     "shell.execute_reply.started": "2021-07-28T09:50:06.873099Z"
    },
    "papermill": {
     "duration": 0.143235,
     "end_time": "2021-07-29T03:15:16.954169",
     "exception": false,
     "start_time": "2021-07-29T03:15:16.810934",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "314"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "military-knife",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-29T03:15:17.065928Z",
     "iopub.status.busy": "2021-07-29T03:15:17.045070Z",
     "iopub.status.idle": "2021-07-29T03:15:17.126430Z",
     "shell.execute_reply": "2021-07-29T03:15:17.125979Z",
     "shell.execute_reply.started": "2021-07-28T09:50:06.977713Z"
    },
    "papermill": {
     "duration": 0.133193,
     "end_time": "2021-07-29T03:15:17.126557",
     "exception": false,
     "start_time": "2021-07-29T03:15:16.993364",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ID_COL  = 'id'\n",
    "TARGET_COL = 'target'\n",
    "TEXT_COL = 'excerpt'\n",
    "DEVICE = torch.device('cuda')\n",
    "\n",
    "preds = 0\n",
    "num_folds = 5\n",
    "random_state = 1234\n",
    "\n",
    "\n",
    "#Create models dir in folder\n",
    "\n",
    "class BERTDataset(Dataset):\n",
    "    def __init__(self, review, model_name, target=None, is_test=False):\n",
    "        self.review = review\n",
    "        self.target = target\n",
    "        self.is_test = is_test\n",
    "        self.tokenizer = transformers.AutoTokenizer.from_pretrained(model_name)\n",
    "        self.max_len = args.max_len\n",
    "        self.model_name = model_name\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.review)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        review = str(self.review[idx])\n",
    "        if args.lower:\n",
    "            review = review.lower()\n",
    "        #review = review.replace('\\n', '')\n",
    "        if args.custom_head and 'roberta' in self.model_name :\n",
    "            pass\n",
    "        else:\n",
    "            review = ' '.join(review.split())\n",
    "        global inputs\n",
    "\n",
    "        if args.dynamic_padding:\n",
    "            inputs = self.tokenizer.encode_plus(\n",
    "                text=review,\n",
    "                truncation=False,\n",
    "                add_special_tokens=True,\n",
    "                padding=False,\n",
    "                return_attention_mask=True,\n",
    "                return_token_type_ids=True\n",
    "            )\n",
    "        else:\n",
    "            inputs = self.tokenizer.encode_plus(\n",
    "                text=review,\n",
    "                truncation=True,\n",
    "                add_special_tokens=True,\n",
    "                max_length=self.max_len,\n",
    "                padding='max_length',\n",
    "                return_attention_mask=True,\n",
    "                return_token_type_ids=True\n",
    "            )\n",
    " \n",
    "        ids = torch.tensor(inputs['input_ids'], dtype=torch.long)\n",
    "        mask = torch.tensor(inputs['attention_mask'], dtype=torch.long)\n",
    "        token_type_ids = torch.tensor(inputs['token_type_ids'], dtype=torch.long)\n",
    "\n",
    "        if self.is_test:\n",
    "            return {\n",
    "                'ids': ids,\n",
    "                'mask': mask,\n",
    "                'token_type_ids': token_type_ids,\n",
    "            }\n",
    "        else:\n",
    "            targets = torch.tensor(self.target[idx], dtype=torch.float)\n",
    "            return {\n",
    "                'ids': ids,\n",
    "                'mask': mask,\n",
    "                'token_type_ids': token_type_ids,\n",
    "                'targets': targets,\n",
    "            }\n",
    "\n",
    "class BERTModel(nn.Module):\n",
    "    def __init__(self, model_name):\n",
    "        super(BERTModel, self).__init__()\n",
    "        self.config = transformers.AutoConfig.from_pretrained(model_name) #, output_hidden_states=True)\n",
    "        self.model_name = model_name\n",
    "        self.rd_feature_len = 0\n",
    "        if args.custom_head:\n",
    "            if 'roberta' in model_name:\n",
    "                self.config.update({\"output_hidden_states\":True, \n",
    "                       \"hidden_dropout_prob\": 0.0,\n",
    "                       \"layer_norm_eps\": 1e-7})      \n",
    "                self.roberta = transformers.AutoModel.from_pretrained( model_name, output_hidden_states=True)\n",
    "                self.regressor = nn.Sequential(\n",
    "                    nn.Linear(768, 1)\n",
    "                )\n",
    "            else:\n",
    "                self.bert = transformers.AutoModel.from_pretrained(model_name , output_hidden_states=True)\n",
    "                self.regressor = nn.Sequential(\n",
    "                    OrderedDict([\n",
    "                        ('dropout0', nn.Dropout(args.use_dropout)),\n",
    "                        ('fc', nn.Linear(args.fc_size, 1))\n",
    "                     ])\n",
    "                    )\n",
    "\n",
    "            self.attention = nn.Sequential(\n",
    "                nn.Linear(args.fc_size, 512),\n",
    "                nn.Tanh(),\n",
    "                nn.Linear(512, 1),\n",
    "                nn.Softmax(dim=1)\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            if args.automodel_seq:\n",
    "                self.bert = transformers.AutoModelForSequenceClassification.from_pretrained(model_name, num_labels = 1, output_hidden_states=False, output_attentions=False)\n",
    "            else:\n",
    "                self.bert = transformers.AutoModel.from_pretrained(model_name , output_hidden_states=True)\n",
    "\n",
    "        if 'distil'  in model_name:\n",
    "            self.layer_norm = nn.LayerNorm(args.hidden_size)\n",
    "            \n",
    "        if args.use_dropout:\n",
    "            if args.multisample_dropout:\n",
    "                self.dropouts = nn.ModuleList([\n",
    "                 nn.Dropout(args.use_dropout) for _ in range(5)\n",
    "                ])\n",
    "            else:\n",
    "                self.dropouts = nn.ModuleList([nn.Dropout(args.use_dropout)])\n",
    "\n",
    "        # Custom head\n",
    "        if args.use_single_fc:\n",
    "            self.fc = nn.Linear(args.fc_size + self.rd_feature_len, 1)\n",
    "        elif args.custom_head:\n",
    "            print('Using custom head')\n",
    "        elif args.automodel_seq:\n",
    "            pass\n",
    "        else:\n",
    "             self.whole_head = nn.Sequential(OrderedDict([\n",
    "            ('dropout0', nn.Dropout(args.use_dropout)),\n",
    "            ('l1', nn.Linear(args.fc_size + self.rd_feature_len, 256)),\n",
    "            ('act1', nn.GELU()),\n",
    "            ('dropout1', nn.Dropout(args.use_dropout)),\n",
    "            ('l2', nn.Linear(256, 1))\n",
    "        ]))\n",
    "                \n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.padding_idx is not None:\n",
    "                module.weight.data[module.padding_idx].zero_()\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "\n",
    "    def forward(self, ids, mask, rd_features=None, token_type_ids=None):\n",
    "        # Returns keys(['last_hidden_state', 'pooler_output', 'hidden_states'])\n",
    "        if token_type_ids is not None:\n",
    "            if args.custom_head and 'roberta' in self.model_name:\n",
    "                output = self.roberta(ids, attention_mask=mask, token_type_ids=token_type_ids, return_dict=True)\n",
    "            else:\n",
    "                output = self.bert(ids, attention_mask=mask, token_type_ids=token_type_ids, return_dict=True)\n",
    "        else:\n",
    "            output = self.bert(ids, attention_mask=mask, return_dict=True)\n",
    "\n",
    "        #output = self.bert(ids, return_dict=True)\n",
    "\n",
    "        # Hidden layer\n",
    "        if args.use_hidden:\n",
    "          if args.use_hidden == 'last':\n",
    "              # Last  hidden states\n",
    "              if args.custom_head and 'bart' in self.model_name:\n",
    "                  output = output['decoder_hidden_states'][-1]\n",
    "              else:\n",
    "                  output = output['hidden_states'][-1]\n",
    "              if not args.custom_head:\n",
    "                  output = output.mean(1)\n",
    "              if args.use_rd_features:\n",
    "                  output = torch.cat((output, rd_features),1)\n",
    "                  output = self.layer_norm(output)\n",
    "\n",
    "          elif args.use_hidden == 'mean_max':\n",
    "              output = output['last_hidden_state']\n",
    "              average_pool = torch.mean(output, 1)\n",
    "              max_pool, _ = torch.max(output, 1)\n",
    "              output = torch.cat((average_pool, max_pool), 1)\n",
    "              if args.use_rd_features:\n",
    "                  output = torch.cat((output, rd_features),1)\n",
    "                  output = self.layer_norm(output)\n",
    "\n",
    "          elif args.use_hidden == 'mean':\n",
    "              hs = output['hidden_states']\n",
    "              seq_output = torch.cat([hs[-1],hs[-2],hs[-3], hs[-4]], dim=-1)\n",
    "              input_mask_expanded = mask.unsqueeze(-1).expand(seq_output.size()).float()\n",
    "              sum_embeddings = torch.sum(seq_output * input_mask_expanded, 1)\n",
    "              sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "              output = sum_embeddings / sum_mask\n",
    "              if args.use_rd_features:\n",
    "                  output = torch.cat((output, rd_features),1)\n",
    "                  output = self.layer_norm(output)\n",
    "        # Pooler\n",
    "        elif args.use_pooler:\n",
    "          output = output['pooler_output']\n",
    "          if args.use_rd_features:\n",
    "              output = torch.cat((output, rd_features),1)\n",
    "              output = self.layer_norm(output)\n",
    "        # Mean of last layer\n",
    "        elif args.use_last_mean:\n",
    "          output = output['last_hidden_state']\n",
    "          input_mask_expanded = mask.unsqueeze(-1).expand(output.size()).float()\n",
    "          sum_embeddings = torch.sum(output * input_mask_expanded, 1)\n",
    "          sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "          output = sum_embeddings / sum_mask\n",
    "          if args.use_rd_features:\n",
    "              output = torch.cat((output, rd_features),1)\n",
    "              output = self.layer_norm(output)\n",
    "        elif args.automodel_seq:\n",
    "            output = output['logits']\n",
    "        # CLS\n",
    "        else:\n",
    "          # Last layer\n",
    "          output = output['last_hidden_state']\n",
    "          # CLS token\n",
    "          output = output[:,0,:]\n",
    "          if args.use_rd_features:\n",
    "              output = torch.cat((output, rd_features),1)\n",
    "              output = self.layer_norm(output)\n",
    "\n",
    "    \n",
    "        \"\"\"\n",
    "        # Dropout if single FC used\n",
    "        if args.use_dropout and args.use_single_fc:\n",
    "          for i, dropout in enumerate(self.dropouts):\n",
    "            if i == 0:\n",
    "                logits = self.fc(dropout(output))\n",
    "            else:\n",
    "                logits += self.fc(dropout(output))\n",
    "          output = logits/len(self.dropouts)\n",
    "        elif args.use_single_fc:\n",
    "            output = self.fc(output)\n",
    "        \"\"\"\n",
    "        \n",
    "        # Custom head\n",
    "        if args.use_single_fc:\n",
    "            output = self.fc(output)\n",
    "        elif args.custom_head:\n",
    "            weights = self.attention(output)\n",
    "            output = torch.sum(weights * output, dim=1)\n",
    "            output = self.regressor(output)\n",
    "        elif args.automodel_seq:\n",
    "            pass\n",
    "        else:\n",
    "            output = self.whole_head(output)\n",
    "        output = output.squeeze(-1).squeeze(-1)\n",
    "        return output\n",
    "    \n",
    "    \n",
    "# %% [code] {\"execution\":{\"iopub.status.busy\":\"2021-06-22T06:53:21.338286Z\",\"iopub.execute_input\":\"2021-06-22T06:53:21.338705Z\",\"iopub.status.idle\":\"2021-06-22T06:53:21.350545Z\",\"shell.execute_reply.started\":\"2021-06-22T06:53:21.338669Z\",\"shell.execute_reply\":\"2021-06-22T06:53:21.349744Z\"}}\n",
    "\n",
    "class CLMCollate:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.seq_dic = defaultdict(int)  ## used to track max_length\n",
    "        self.batch_record = defaultdict(list)\n",
    "        self.bn = 0\n",
    "\n",
    "    def __call__(self,batch):\n",
    "        out = {'ids' :[],\n",
    "               'mask':[],\n",
    "               'token_type_ids':[],\n",
    "               'targets':[],\n",
    "               'errors': [],\n",
    "               'rd_features': [],\n",
    "               'bins': []\n",
    "        }\n",
    "\n",
    "        for i in batch:\n",
    "            for k,v in i.items():\n",
    "                out[k].append(v)\n",
    "\n",
    "        if args.dynamic_padding:\n",
    "            max_pad =0\n",
    "\n",
    "            for p in out['ids']:\n",
    "                if max_pad < len(p):\n",
    "                    max_pad = len(p)\n",
    "\n",
    "        else:\n",
    "            max_pad = args.max_len\n",
    "\n",
    "\n",
    "        self.batch_record[str(self.bn)] = [len(x) for x in out['ids']]\n",
    "        self.seq_dic[str(self.bn)] = max_pad\n",
    "        self.bn+=1\n",
    "        for i in range(len(batch)):\n",
    "            input_id = out['ids'][i]\n",
    "            att_mask = out['mask'][i]\n",
    "            token_type_id = out['token_type_ids'][i]\n",
    "            text_len = len(input_id)\n",
    "\n",
    "            # Add pad based on text len in batch\n",
    "            out['ids'][i] = np.hstack((out['ids'][i].detach().numpy(), [1] * (max_pad - text_len))[:max_pad])\n",
    "            out['mask'][i] = np.hstack((out['mask'][i].detach().numpy(), [0] * (max_pad - text_len))[:max_pad])\n",
    "            out['token_type_ids'][i] = np.hstack((out['token_type_ids'][i].detach().numpy(), [0] * (max_pad - text_len))[:max_pad])\n",
    "\n",
    "        out['ids'] = torch.tensor(out['ids'],dtype=torch.long)\n",
    "        out['mask'] = torch.tensor(out['mask'],dtype=torch.long)\n",
    "        out['token_type_ids'] = torch.tensor(out['token_type_ids'],dtype=torch.long)\n",
    "        out['targets'] = torch.tensor(out['targets'],dtype=torch.float)\n",
    "        out['errors'] = torch.tensor(out['errors'],dtype=torch.float)\n",
    "        out['rd_features'] = torch.tensor(out['rd_features'],dtype=torch.float)\n",
    "\n",
    "        return out\n",
    "    \n",
    "    \n",
    "def get_bert_predictions(test_data, model_name, model_path):\n",
    "        print('Getting BERT Embeddings')\n",
    "        \"\"\"\n",
    "        This function validates the model for one epoch through all batches of the valid dataset\n",
    "        It also returns the validation Root mean squared error for assesing model performance.\n",
    "        \"\"\"\n",
    "        BertModel = BERTModel(model_name=model_name)\n",
    "        #print(BertModel) \n",
    "        BertModel.to(DEVICE) \n",
    "        BertModel.load_state_dict(torch.load(model_path), strict=True)\n",
    "\n",
    "        test_set = BERTDataset(\n",
    "            review = test_data[TEXT_COL].values,\n",
    "            target = None,\n",
    "            model_name = model_name,\n",
    "            is_test = True\n",
    "\n",
    "        )\n",
    "\n",
    "        if args.dynamic_padding:\n",
    "            sequence = CLMCollate()\n",
    "            test_data_loader = DataLoader(\n",
    "                test_set,\n",
    "                batch_size = Config.VALID_BS,\n",
    "                collate_fn=sequence,\n",
    "                shuffle = False,\n",
    "                num_workers=8\n",
    "            )\n",
    "        else:\n",
    "            test_data_loader = DataLoader(\n",
    "                test_set,\n",
    "                batch_size = Config.VALID_BS,\n",
    "                shuffle = False,\n",
    "                num_workers=8\n",
    "            )\n",
    "\n",
    "        prog_bar = tqdm(enumerate(test_data_loader), total=len(test_data_loader))\n",
    "        BertModel.eval()\n",
    "        all_predictions = []\n",
    "        with torch.no_grad():\n",
    "            for idx, inputs in prog_bar:\n",
    "                ids = inputs['ids'].to(DEVICE, dtype=torch.long)\n",
    "                mask = inputs['mask'].to(DEVICE, dtype=torch.long)\n",
    "                ttis = inputs['token_type_ids'].to(DEVICE, dtype=torch.long)\n",
    "                if 'distil' in model_name or 'bart' in model_name:\n",
    "                    ttis = None\n",
    "                outputs = BertModel(ids=ids, mask=mask, token_type_ids=ttis)\n",
    "                all_predictions.extend(outputs.cpu().detach().numpy())\n",
    "\n",
    "        return all_predictions\n",
    "\n",
    "df = pd.read_csv('../input/commonlitreadabilityprize/test.csv')\n",
    "pred_df = pd.DataFrame()\n",
    "\n",
    "class Config:\n",
    "    seed = 1234\n",
    "    NB_EPOCHS = 10\n",
    "    LR = 4e-5\n",
    "    N_SPLITS = 5\n",
    "    TRAIN_BS = 32\n",
    "    VALID_BS = 64\n",
    "    DBERT_MODELS = ['distilbert', 'xlnet', 't5']\n",
    "    FILE_NAME = '../input/train.csv'\n",
    "    scaler = GradScaler()\n",
    "\n",
    "# %% [markdown]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "falling-sender",
   "metadata": {
    "papermill": {
     "duration": 0.040075,
     "end_time": "2021-07-29T03:15:17.203473",
     "exception": false,
     "start_time": "2021-07-29T03:15:17.163398",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## LB 0.464-Roberta-large\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "multiple-chester",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-29T03:15:17.286897Z",
     "iopub.status.busy": "2021-07-29T03:15:17.286228Z",
     "iopub.status.idle": "2021-07-29T03:17:18.182007Z",
     "shell.execute_reply": "2021-07-29T03:17:18.182385Z",
     "shell.execute_reply.started": "2021-07-28T09:50:07.04293Z"
    },
    "papermill": {
     "duration": 120.940745,
     "end_time": "2021-07-29T03:17:18.182549",
     "exception": false,
     "start_time": "2021-07-29T03:15:17.241804",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting BERT Embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting BERT Embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting BERT Embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting BERT Embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting BERT Embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.01it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1297"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class BERTModelConfig():\n",
    "    lower = False\n",
    "    use_dropout = 0.1\n",
    "    pretrained_model = False\n",
    "    use_hidden = False\n",
    "    hidden_size = 1024\n",
    "    max_len = 250\n",
    "    fc_size = 1024\n",
    "    use_single_fc = False\n",
    "    use_pooler = False\n",
    "    use_last_mean = False\n",
    "    multisample_dropout = False\n",
    "    use_rd_features = False\n",
    "    use_hidden_4 = False \n",
    "    custom_head = False\n",
    "    dynamic_padding = False\n",
    "    automodel_seq = False\n",
    "\n",
    "args = BERTModelConfig()\n",
    "\n",
    "    \n",
    "pred_df['fold0'] = get_bert_predictions(df, model_name='../input/torch-bert-large-models/roberta-large' ,\n",
    "                                         model_path='../input/roberta-large-0708/roberta_l_0708/bert_model_fold0.bin'\n",
    "                                       )\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "pred_df['fold1'] = get_bert_predictions(df, model_name='../input/torch-bert-large-models/roberta-large' ,\n",
    "                                         model_path='../input/roberta-large-0708/roberta_l_0708/bert_model_fold1.bin'\n",
    "                                       ) \n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "pred_df['fold2'] = get_bert_predictions(df, model_name='../input/torch-bert-large-models/roberta-large' ,\n",
    "                                         model_path='../input/roberta-large-0708/roberta_l_0708/bert_model_fold2.bin'\n",
    "                                       )\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "pred_df['fold3'] = get_bert_predictions(df, model_name='../input/torch-bert-large-models/roberta-large' ,\n",
    "                                         model_path='../input/roberta-large-0708/roberta_l_0708/bert_model_fold3.bin'\n",
    "                                       )\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "pred_df['fold4'] = get_bert_predictions(df, model_name='../input/torch-bert-large-models/roberta-large' ,\n",
    "                                         model_path='../input/roberta-large-0708/roberta_l_0708/bert_model_fold4.bin'\n",
    "                                       )\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "square-coordinate",
   "metadata": {
    "papermill": {
     "duration": 0.041592,
     "end_time": "2021-07-29T03:17:18.266361",
     "exception": false,
     "start_time": "2021-07-29T03:17:18.224769",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## LB 0.465 Funnel large "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "official-bradford",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-29T03:17:18.358037Z",
     "iopub.status.busy": "2021-07-29T03:17:18.357440Z",
     "iopub.status.idle": "2021-07-29T03:19:39.948955Z",
     "shell.execute_reply": "2021-07-29T03:19:39.948268Z",
     "shell.execute_reply.started": "2021-07-28T09:52:22.209876Z"
    },
    "papermill": {
     "duration": 141.641135,
     "end_time": "2021-07-29T03:19:39.949115",
     "exception": false,
     "start_time": "2021-07-29T03:17:18.307980",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting BERT Embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting BERT Embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting BERT Embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting BERT Embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting BERT Embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.83it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1569"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class BERTModelConfig():\n",
    "    lower = False\n",
    "    use_dropout = 0.1\n",
    "    pretrained_model = False\n",
    "    use_hidden = False\n",
    "    hidden_size = 1024\n",
    "    max_len = 250\n",
    "    fc_size = 1024\n",
    "    use_single_fc = False\n",
    "    use_pooler = False\n",
    "    use_last_mean = False\n",
    "    multisample_dropout = False\n",
    "    use_rd_features = False\n",
    "    custom_head = False\n",
    "    dynamic_padding = False\n",
    "    automodel_seq = False\n",
    "\n",
    "args = BERTModelConfig()\n",
    "\n",
    "    \n",
    "pred_df['fold5'] = get_bert_predictions( df,\n",
    "                                         model_name='../input/funneltransformerlarge/funnel-transformer-large' ,\n",
    "                                         model_path='../input/funnel-large-0703/funnel_l_0702/bert_model_fold0.bin'\n",
    "                                       )\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "pred_df['fold6'] = get_bert_predictions(df, \n",
    "                                         model_name='../input/funneltransformerlarge/funnel-transformer-large' ,\n",
    "                                         model_path='../input/funnel-large-0703/funnel_l_0702/bert_model_fold1.bin'\n",
    "                                       )\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "pred_df['fold7'] = get_bert_predictions(df, \n",
    "                                         model_name='../input/funneltransformerlarge/funnel-transformer-large' ,\n",
    "                                         model_path='../input/funnel-large-0703/funnel_l_0702/bert_model_fold2.bin'\n",
    "                                       )\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "pred_df['fold8'] = get_bert_predictions(df, \n",
    "                                         model_name='../input/funneltransformerlarge/funnel-transformer-large' ,\n",
    "                                         model_path='../input/funnel-large-0703/funnel_l_0702/bert_model_fold3.bin'\n",
    "                                       )\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "pred_df['fold9'] = get_bert_predictions(df, \n",
    "                                         model_name='../input/funneltransformerlarge/funnel-transformer-large' ,\n",
    "                                         model_path='../input/funnel-large-0703/funnel_l_0702/bert_model_fold4.bin'\n",
    "                                       )\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "positive-clearing",
   "metadata": {
    "papermill": {
     "duration": 0.056844,
     "end_time": "2021-07-29T03:19:40.057007",
     "exception": false,
     "start_time": "2021-07-29T03:19:40.000163",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## LB 0.466 - Deberta-large\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "wooden-flooring",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-29T03:19:40.176100Z",
     "iopub.status.busy": "2021-07-29T03:19:40.175333Z",
     "iopub.status.idle": "2021-07-29T03:22:15.326997Z",
     "shell.execute_reply": "2021-07-29T03:22:15.326455Z",
     "shell.execute_reply.started": "2021-07-28T09:55:04.051779Z"
    },
    "papermill": {
     "duration": 155.219017,
     "end_time": "2021-07-29T03:22:15.327144",
     "exception": false,
     "start_time": "2021-07-29T03:19:40.108127",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting BERT Embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting BERT Embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting BERT Embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting BERT Embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting BERT Embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.44it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6532"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class BERTModelConfig():\n",
    "    lower = False\n",
    "    use_dropout = 0.1\n",
    "    pretrained_model = False\n",
    "    use_hidden = False\n",
    "    hidden_size = 1024\n",
    "    max_len = 250\n",
    "    fc_size = 1024\n",
    "    use_single_fc = False\n",
    "    use_pooler = False\n",
    "    use_last_mean = False\n",
    "    multisample_dropout = False\n",
    "    use_rd_features = False\n",
    "    custom_head = False\n",
    "    dynamic_padding = False\n",
    "    automodel_seq = False\n",
    "\n",
    "args = BERTModelConfig()\n",
    "\n",
    "    \n",
    "pred_df['fold10'] = get_bert_predictions(df, model_name='../input/torch-bert-large-models/deberta-large' ,\n",
    "                                         model_path='../input/deberta-large-0627/deberta_l_0627/bert_model_fold0.bin'\n",
    "                                       )\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "pred_df['fold11'] = get_bert_predictions(df, model_name='../input/torch-bert-large-models/deberta-large' ,\n",
    "                                         model_path='../input/deberta-large-0627/deberta_l_0627/bert_model_fold1.bin'\n",
    "                                       ) \n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "pred_df['fold12'] = get_bert_predictions(df, model_name='../input/torch-bert-large-models/deberta-large' ,\n",
    "                                         model_path='../input/deberta-large-0627/deberta_l_0627/bert_model_fold2.bin'\n",
    "                                       )\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "pred_df['fold13'] = get_bert_predictions(df, model_name='../input/torch-bert-large-models/deberta-large' ,\n",
    "                                         model_path='../input/deberta-large-0627/deberta_l_0627/bert_model_fold3.bin'\n",
    "                                       )\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "pred_df['fold14'] = get_bert_predictions(df, model_name='../input/torch-bert-large-models/deberta-large' ,\n",
    "                                         model_path='../input/deberta-large-0627/deberta_l_0627/bert_model_fold4.bin'\n",
    "                                       )\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "packed-layout",
   "metadata": {
    "papermill": {
     "duration": 0.05523,
     "end_time": "2021-07-29T03:22:15.439259",
     "exception": false,
     "start_time": "2021-07-29T03:22:15.384029",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## LB 0.467 roberta base \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "foster-ecology",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-29T03:22:15.558491Z",
     "iopub.status.busy": "2021-07-29T03:22:15.557946Z",
     "iopub.status.idle": "2021-07-29T03:23:01.486620Z",
     "shell.execute_reply": "2021-07-29T03:23:01.486207Z",
     "shell.execute_reply.started": "2021-07-28T09:57:55.430231Z"
    },
    "papermill": {
     "duration": 45.992469,
     "end_time": "2021-07-29T03:23:01.486775",
     "exception": false,
     "start_time": "2021-07-29T03:22:15.494306",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting BERT Embeddings\n",
      "Using custom head\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting BERT Embeddings\n",
      "Using custom head\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting BERT Embeddings\n",
      "Using custom head\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting BERT Embeddings\n",
      "Using custom head\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting BERT Embeddings\n",
      "Using custom head\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.50it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class BERTModelConfig():\n",
    "    lower = False\n",
    "    use_dropout = 0.1\n",
    "    pretrained_model = False\n",
    "    use_hidden = 'last'\n",
    "    hidden_size = 1024\n",
    "    max_len = 248\n",
    "    fc_size = 768\n",
    "    use_single_fc = False\n",
    "    use_pooler = False\n",
    "    use_last_mean = False\n",
    "    multisample_dropout = False\n",
    "    use_rd_features = False\n",
    "    custom_head = True\n",
    "    dynamic_padding = False\n",
    "    automodel_seq = False\n",
    "\n",
    "args = BERTModelConfig()\n",
    "\n",
    "    \n",
    "pred_df['fold15'] = get_bert_predictions( df,\n",
    "                                         model_name='../input/roberta-base' ,\n",
    "                                         model_path='../input/robertapublb0467/model_1.pth'\n",
    "                                       )\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "pred_df['fold16'] = get_bert_predictions(df, \n",
    "                                         model_name='../input/roberta-base' ,\n",
    "                                         model_path='../input/robertapublb0467/model_2.pth'\n",
    "                                       )\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "pred_df['fold17'] = get_bert_predictions(df, \n",
    "                                         model_name='../input/roberta-base' ,\n",
    "                                         model_path='../input/robertapublb0467/model_3.pth'\n",
    "                                       )\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "pred_df['fold18'] = get_bert_predictions(df, \n",
    "                                         model_name='../input/roberta-base' ,\n",
    "                                         model_path='../input/robertapublb0467/model_4.pth'\n",
    "                                       )\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "pred_df['fold19'] = get_bert_predictions(df, \n",
    "                                         model_name='../input/roberta-base' ,\n",
    "                                         model_path='../input/robertapublb0467/model_5.pth'\n",
    "                                       )\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "generic-employer",
   "metadata": {
    "papermill": {
     "duration": 0.061134,
     "end_time": "2021-07-29T03:23:01.609324",
     "exception": false,
     "start_time": "2021-07-29T03:23:01.548190",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## LB 0.468 - electra-large-discriminator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "closed-mortgage",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-29T03:23:01.741796Z",
     "iopub.status.busy": "2021-07-29T03:23:01.741165Z",
     "iopub.status.idle": "2021-07-29T03:25:18.035820Z",
     "shell.execute_reply": "2021-07-29T03:25:18.035366Z",
     "shell.execute_reply.started": "2021-07-28T09:58:46.754977Z"
    },
    "papermill": {
     "duration": 136.365937,
     "end_time": "2021-07-29T03:25:18.035965",
     "exception": false,
     "start_time": "2021-07-29T03:23:01.670028",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting BERT Embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting BERT Embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting BERT Embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting BERT Embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting BERT Embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.89it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1297"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "class BERTModelConfig():\n",
    "    lower = False\n",
    "    use_dropout = 0.1\n",
    "    pretrained_model = False\n",
    "    use_hidden = False\n",
    "    hidden_size = 1024\n",
    "    max_len = 250\n",
    "    fc_size = 1024\n",
    "    use_single_fc = False\n",
    "    use_pooler = False\n",
    "    use_last_mean = False\n",
    "    multisample_dropout = False\n",
    "    use_rd_features = False\n",
    "    custom_head = False\n",
    "    dynamic_padding = False\n",
    "    automodel_seq = False\n",
    "\n",
    "args = BERTModelConfig()\n",
    "\n",
    "    \n",
    "pred_df['fold20'] = get_bert_predictions(df, model_name='../input/torch-bert-large-models/electra-large-discriminator' ,\n",
    "                                         model_path='../input/electra-large-0630/electra_large_0630/bert_model_fold0.bin'\n",
    "                                       )\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "pred_df['fold21'] = get_bert_predictions(df, model_name='../input/torch-bert-large-models/electra-large-discriminator' ,\n",
    "                                         model_path='../input/electra-large-0630/electra_large_0630/bert_model_fold1.bin'\n",
    "                                       ) \n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "pred_df['fold22'] = get_bert_predictions(df, model_name='../input/torch-bert-large-models/electra-large-discriminator' ,\n",
    "                                         model_path='../input/electra-large-0630/electra_large_0630/bert_model_fold2.bin'\n",
    "                                       )\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "pred_df['fold23'] = get_bert_predictions(df, model_name='../input/torch-bert-large-models/electra-large-discriminator' ,\n",
    "                                         model_path='../input/electra-large-0630/electra_large_0630/bert_model_fold3.bin'\n",
    "                                       )\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "pred_df['fold24'] = get_bert_predictions(df, model_name='../input/torch-bert-large-models/electra-large-discriminator' ,\n",
    "                                         model_path='../input/electra-large-0630/electra_large_0630/bert_model_fold4.bin'\n",
    "                                       )\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "golden-detail",
   "metadata": {
    "papermill": {
     "duration": 0.072812,
     "end_time": "2021-07-29T03:25:18.181835",
     "exception": false,
     "start_time": "2021-07-29T03:25:18.109023",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Weighted Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aware-reducing",
   "metadata": {
    "papermill": {
     "duration": 0.071574,
     "end_time": "2021-07-29T03:25:18.327868",
     "exception": false,
     "start_time": "2021-07-29T03:25:18.256294",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "regression_pred_df = pd.DataFrame()\n",
    "regression_pred_group1_df = pd.DataFrame()\n",
    "regression_pred_group2_df = pd.DataFrame()\n",
    "\n",
    "group1_cols = ['fold0', 'fold1', 'fold2', 'fold3','fold4',\n",
    "               'fold5','fold6', 'fold7', 'fold8','fold9',\n",
    "              'fold10', 'fold11', 'fold12', 'fold13','fold14',\n",
    "              ]\n",
    "group2_cols = ['fold15', 'fold16', 'fold17', 'fold18','fold19']\n",
    "regression_pred_group1_df['target'] = pred_df[group1_cols].mean(axis=1).values.tolist()\n",
    "regression_pred_group2_df['target'] = pred_df[group2_cols].mean(axis=1).values.tolist()\n",
    "\n",
    "regression_pred_df['target'] = regression_pred_group1_df['target'] * 0.6 + regression_pred_group2_df['target'] * 0.4\n",
    "regression_pred_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equipped-niagara",
   "metadata": {
    "papermill": {
     "duration": 0.074419,
     "end_time": "2021-07-29T03:25:18.474072",
     "exception": false,
     "start_time": "2021-07-29T03:25:18.399653",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Simple mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "moving-gibson",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-29T03:25:18.626808Z",
     "iopub.status.busy": "2021-07-29T03:25:18.625991Z",
     "iopub.status.idle": "2021-07-29T03:25:18.639248Z",
     "shell.execute_reply": "2021-07-29T03:25:18.640101Z",
     "shell.execute_reply.started": "2021-07-28T10:01:19.451505Z"
    },
    "papermill": {
     "duration": 0.095223,
     "end_time": "2021-07-29T03:25:18.640316",
     "exception": false,
     "start_time": "2021-07-29T03:25:18.545093",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 1)\n",
      "     target\n",
      "0 -0.484693\n",
      "1 -0.556209\n",
      "2 -0.494541\n",
      "3 -2.272735\n",
      "4 -1.838250\n",
      "5 -1.297987\n",
      "6  0.220606\n"
     ]
    }
   ],
   "source": [
    "regression_pred_df = pd.DataFrame()\n",
    "regression_pred_df['target'] = pred_df.mean(axis=1).values.tolist()\n",
    "print(regression_pred_df.shape)\n",
    "print(regression_pred_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "horizontal-bride",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-29T03:25:18.810236Z",
     "iopub.status.busy": "2021-07-29T03:25:18.809446Z",
     "iopub.status.idle": "2021-07-29T03:25:18.813231Z",
     "shell.execute_reply": "2021-07-29T03:25:18.812776Z",
     "shell.execute_reply.started": "2021-07-28T10:01:19.4728Z"
    },
    "papermill": {
     "duration": 0.088251,
     "end_time": "2021-07-29T03:25:18.813357",
     "exception": false,
     "start_time": "2021-07-29T03:25:18.725106",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c0f722661</td>\n",
       "      <td>-0.291971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f0953f0a5</td>\n",
       "      <td>-0.526356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0df072751</td>\n",
       "      <td>-0.597451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04caf4e0c</td>\n",
       "      <td>-2.294861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0e63f8bea</td>\n",
       "      <td>-1.865334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12537fe78</td>\n",
       "      <td>-1.184783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>965e592c0</td>\n",
       "      <td>0.254294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id    target\n",
       "0  c0f722661 -0.291971\n",
       "1  f0953f0a5 -0.526356\n",
       "2  0df072751 -0.597451\n",
       "3  04caf4e0c -2.294861\n",
       "4  0e63f8bea -1.865334\n",
       "5  12537fe78 -1.184783\n",
       "6  965e592c0  0.254294"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs_pred_df \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "still-holmes",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-29T03:25:18.974654Z",
     "iopub.status.busy": "2021-07-29T03:25:18.974051Z",
     "iopub.status.idle": "2021-07-29T03:25:19.110649Z",
     "shell.execute_reply": "2021-07-29T03:25:19.111367Z",
     "shell.execute_reply.started": "2021-07-28T10:01:19.485426Z"
    },
    "papermill": {
     "duration": 0.219345,
     "end_time": "2021-07-29T03:25:19.111611",
     "exception": false,
     "start_time": "2021-07-29T03:25:18.892266",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          id    target\n",
      "0  c0f722661 -0.388332\n",
      "1  f0953f0a5 -0.541283\n",
      "2  0df072751 -0.545996\n",
      "3  04caf4e0c -2.283798\n",
      "4  0e63f8bea -1.851792\n"
     ]
    }
   ],
   "source": [
    "sub_df = pd.read_csv('../input/commonlitreadabilityprize/sample_submission.csv')\n",
    "# Mean of pairs and regression approach\n",
    "sub_df['target'] = (pairs_pred_df['target'] * 0.5) + (regression_pred_df['target'] * 0.5)\n",
    "sub_df.to_csv('submission.csv', index=False)\n",
    "print(sub_df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1023.942587,
   "end_time": "2021-07-29T03:25:21.805066",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-07-29T03:08:17.862479",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
